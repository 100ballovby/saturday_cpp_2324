#include <iostream>
#include <vector>
#include <string>
#include <iterator>  // добавить заголовочный файл iterator
using namespace std;


void insertionSort(vector<int> &array, int n) {
    for (int i = 2; i <= n; i++) {  // просматриваем массив по индексам
        int j = i - 1;
        int tmp = array[j];  // сохраняем значение элемента во временной переменной
        while(array[j - 1] > tmp) {  // перемещаем все элементы больше вставляемого на одно место вправо
            array[j] = array[j - 1];
            j--;
        }
        array[j] = tmp;  // помещаем значение временной переменной в освободившееся место
    }
}

int summ(vector<int> &array, int n) {
    int sum = 0;
    for (int i = 0; i < n; i++) {
        sum += array[i];
    }
    return sum;
}

/* Данна программа выполняет одно присваивание до начала цикла, n присваиваний внутри цикла и
 * возвращает сумму после. Т.о. для выполнения требуется n+2 простых операций. Поэтому, сложность
 * алгоритма будет равна O(n + 2)
 */

void matrixAddition(int **m1, int **m2, int **dest, int n) {
    for (int i = 0; i < n; i++) {  // константный множитель
        for (int j = 0; j < n; j++) {
            dest[i][j] = m1[i][j] + m2[i][j];
        }
    }
}

/* Алгоритм состоит из двух вложенных циклов. Внутренний цикл выполняет n итераций, причем каждый
 * шаг состоит их двух простых действий: сложение и присваивание. Можно сделать вывод, что
 * сложность внутреннего цикла равна O(2n). Внешний цикл также делает n-итераций, но вместо
 * простых операций, он запускает внутренний цикл. Т.о. можно сказать, что внешний цикл (а
 * значит и алгоритм) имеет сложность O(n * 2 * n) = (2n^2). Если убрать константы, можно
 * будет получить просто O(n^2). Констатные множители можно опустить, посколько они не влияют
 * на поведение алгоритма. Однако они имеют больше значение практическое, так как алгоритм с той же
 * сложность, но вдвое быстрее, всегда предпочтителен.
 *
 * Ответ на вопрос "Сложность этого алгоритма?" - O(2n^2) / O(n^2)
 */


void function(int **dest, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            dest[i][j] = 1;
        }
    } // n^2

    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            for (int k = 0; k < n; k++) {
                dest[i][j] = 2;
            }
        }
    } // n^3
}
/* Функция выполняет дважды вложенный цикл с суммарной сложностью O(n^2),
 * а затем трижды выполняет вложенный цикл со сложностью O(n^3). Как считать сложность
 * такого алгоритма?
 * Сложность алгоритма составляет: O(n^3 + n^2). А посколько n^3 больше, чем n^2, мы можем уменьшить
 * сложность алгоритма до O(n^3).
 */

/* Есть два алгоритма: сложность первого O(log n) и выполняет log n + 1000000000 операций.
 * Сложность второго алгоритма составляет O(n^2), а на практике требует n^2+10 операций.
 * Несмотря на то, что время выполнения первого алгоритма гораздо быстрее, потому что log(n) < n^2,
 * на маленьком количестве элементов, первый алгоритм будет проигрывать в скорости второму, потому что:
 *
 * array[100] -> log(100) = 2 + 1 000 000 000 = 1 000 000 002 секунды выполнения
 * array[100] -> 100^2 = 10000 + 10 = 10010 секунд выполнения
 *
 * НО! На больших входных данных, ситуация меняется:
 *
 * array[1 000 000 000] -> log(1 000 000 000) = 9 + 1 000 000 000 = 1 000 000 009 секунд выполнения
 * array[1 000 000 000] -> 1 000 000 000 ^ 2 = 1e+18 + 10 = 1e+18 секунд выполнения
 */

/* Часто встречающиеся функции времени выполнения:
 * 1) O(1) - если алгоритм выполняет одинаковое количество оперций вне зависимости от размера
 * входах данных, он имеет сложность O(1).
 * 2) O(log n) - Когда сложность алгоритма логарифмическая, программа становится лишь немного
 * межденнее по мере роста n. При умножении размера входных данных на коэффициент основания логарифма
 * время выполнения алгоритма увеличивается только на константу.
 * Для хранения числа n требуется log2(n + 1), т.о. логарифмическое время работы пропорционально
 * числу битов, используемых для хранения n. При умножении диапазона на два число битов будет увеличено
 * на единицу. Аналогично, при увеличении размера входных данных в два раза время работы увеличится на
 * единицу. Например, когда размер входных данных равен миллиарду, время выполнения равно 30. Когда
 * размер входных данных равен двум миллиардам, время выполнения равно 31.
 * 3) O(n) - Если время выполнения программы является линейным, то обычно каждый входной
 * элемент подвергается обработке с постоянной сложностью. Когда n равно миллиону, время исполнения
 * также равно миллиону. Если n удваивается, время работы также удваивается. Нахождение
 * наибольшего/наименьшего элемента в несортированном массиве, является примером случая алгоритма O(n)
 * 4) O(n^2) - Если алгоритм перебирает все входные данные и на каждой итерации перебирает их снова,
 * он имеет квадратичную сложность. В качестве примера программа, которая выводит все возможные
 * пары из элементов массива.
 */

void display_pairs(int *array, int n) {
    int count = 0;
    for (int i = 0; i < n; i++) {  // перебирает все элементы массива
        for (int j = 0; j < n; j++) {  // перебирает все элементы массива во второй раз
            count++;
            cout << "Pair #" << count << ":" << array[i] << "-" << array[j] << endl;
        }
    }
}

int main() {
    vector<int> array { 5, 2, 1, 6, 3, 7, 4 };
    insertionSort(array, array.size());
    // вывести отсортированный массив
    for (int num : array) {
        cout << num << " ";
    }
    cout << endl;

    return 0;
}


